% Chapter 1

 \chapter{Introduction} % Main chapter title

\label{chapter1} % For referencing the chapter elsewhere, use \ref{Chapter1} 

\lhead{Chapter 1. \emph{Introduction}} % This is for the header on each page - perhaps a shortened title

%----------------------------------------------------------------------------------------
The activity of decision making pervades everyday life of human beings. For instance, we choose what type of food to have for dinner or what road to take to go to work. However, not all types of decisions that we have to commit to might be as straightforward as the ones above. For instance, deciding whether or not to shut down a nuclear source term due to a malfunctioning on site or committing to a policy concerning climate change to reduce CO\textsubscript{2} emissions at world level requires an accurate reflection about the consequences of the available courses of action. In these situations the Decision Maker (DM) - the individual who has the responsibility, accountability and authority to determine a decision and possibly implement it -  needs to make choices in complex and evolving environments, described through multiple and interdependent processes with many associated measurements \citep{Bennet2009}. 

Empirical research has shown that humans exhibit, even in very simple situations, a high number of inconsistencies when making decisions  \citep{Tversky1974}. Our actions can often be said to be \textit{irrational} - according to some canons of rationality that we  discuss in more details in the following. Additional research has further shown however that the number of fallacies DMs may incur in can greatly decrease if they are properly supported during the decision making process \citep[see e.g.][]{Bhandari2008}. Thinking about our everyday life, when we are faced with a decision problem involving elements we are not familiar with, we often seek for the help of a person with the relative expertise in the appropriate field. We say that an individual has expertise, and therefore is an \textit{expert}, if he/she has a comprehensive and authoritative knowledge of a specific field, not possessed by many people \citep{Caley2014}. 

Expert Systems (ESs), usually computer-based, aim at simulating the reasoning of experts and therefore at providing the required support to DMs by codifying expert knowledge. These usually use artificial intelligence techniques to process information, learn, reason and make predictions, thus enhancing the process of decision making. Within the information systems' literature, ESs are considered as a special class of \textbf{Decision Support Systems (DSSs)}, usually called intelligent DSSs \citep{Marakas2003}. There is a large number of definitions of what a DSS is. Here we follow \citet{French2009} saying that a ``DSS is a computer-based system that supports the decision making process, helping DMs to understand the problem before them and to form and explore the implications of their judgements, and hence to make a decision upon understanding''. Both DSSs and ESs can provide great benefits to DMs since these combine the knowledge of several experts into a reusable tool that quickly processes information and makes inferences. For the purpose of this thesis we use the two terms interchangeably, but we note that the term ES is more common within the statistical community, whilst DSS appears more frequently in the information systems' literature.

Although DSSs have now been developed and used in practice in a variety of domains, we argue in this thesis that  DMs can only be properly supported in \textit{complex} current situations by an \textbf{Integrating Decision Support System (IDSS)} \citep{Leonelli2015,Smith2015}, which networks together different DSSs into a unique coherent supporting tool. Here, briefly, we notice that this is true mainly for two reasons. First, current applications, as for example nuclear emergency management, require knowledge on a variety of domains, which can be difficult to synthesise into a unique system. Second, the network structure connecting different DSSs provides the basis for both distributed computations and reasoning, increasing the comprehensibility of the analyses performed and the speed of computations, so that the IDSS can be used in real-time. 

In order to support more strongly our statements, and therefore highlight both the relevance and the contributions of this thesis, we need to provide a short history of the development of ESs within the statistical literature. In Section \ref{sec:early} we describe early ESs in use in the last century. We  take a little digression in Section \ref{sec:nuclear} to illustrate the use of ESs for nuclear emergency management, summarising the discussion in \citet{Leonelli2013}. In Section \ref{sec:current} we describe modern statistical DSSs and discuss how these address the needs of current applications. Section \ref{sec:decision} highlights the need for and the main features of IDSSs  by noticing the flaws of current DSSs in properly supporting the decision making process in complex domains. We then conclude the chapter by specifying the contributions and the structure of the thesis in Sections \ref{sec:contributions} and \ref{sec:structure} respectively. 
    
\section{Early Probabilistic Expert Systems}
\label{sec:early}
At their inception, ESs were only able to model deterministic domains. Their knowledge base - comprising facts about the world and an inference engine  -  consisted of a set of deterministic rules and, for this reason, such deterministic systems are often referred to as rule-based ESs. \citet{Castillo1997b}, whilst including an overview of rule-based systems and their domains of application, recognised that the deterministic assumption is too restrictive in most, if not all, of the cases. As the complexity of the problems addressed by ESs increased, a slow recognition of the need for introducing measures of uncertainty began to be appreciated. Uncertainty, as firmly stated by \citet{French95}, is part of any decision analysis, arising, among the others, from physical randomness, imprecision of meaning and various estimates, and therefore needs to be properly addressed. 

However at first, probabilistic reasoning was not considered as a viable option for uncertainty modelling in ESs for a variety of reason: probability theory was thought as epistemologically inadequate in this context, it required the specification of an infeasible number of probabilities and there was no technology to feasibly perform the appropriate computations. For these and other reasons, different approaches to the representation of uncertainty were followed, as for example non-monotonic and fuzzy logic, certainty factors and Dempster-Shafer belief functions \citep[see e.g.][]{Gabbay1985, Klir1995, Buchanan1984, Shafer1976}. However, around the 1980s, solutions to the three main criticism of the use of probability in ESs began to appear, which allowed for a wider applicability of probabilistic ESs.

At that time the frequentist interpretation of probability was the most widespread within the statistical community. This school of thought defines probability as the long-run frequency of occurrence in repeated events: probability is an intrinsic property of the system being observed.  Clearly, this definition of probability does not easily fit the process of supporting DMs, since decision situations are unique and human interventions change the observed system. The subjective Bayesian definition of probability, which was starting to be appreciated, defines it as the degree of belief about the state of the world under consideration by the observer. This  naturally provides an interpretation of probability that can be used for uncertainty modelling in ESs. This is because within the Bayesian framework probability is not any more an intrinsic property of the system, but belongs to the DM and represents her own beliefs about it. 

It was also recognised that graphical representations of the relationships between random variables could be underpinned by conditional independences \citep[][]{Dawid1979}, enabling large dimensional joint probabilities to be written as  products of local distributions of smaller dimension, thus requiring less probability specifications. Formal statistical graphical models then began to be defined, as for example Markov Networks (MNs) and Bayesian Networks (BNs) \citep[see e.g.][and Sections \ref{sec:BN} and \ref{sec:UG}]{Lauritzen1996a,Pearl1988a}, which, exploiting conditional independences, represent the qualitative structure of a multivariate random vector through a graph. Techniques exploiting the graph structure, as for instance triangulation \citep[see e.g.][]{Spiegelhalter1993} and Bayesian stochastic numerical approximations \citep[see e.g.][]{Gilks1996}, enabled probability calculations over the graph to be quickly and feasibly computed by ESs. 

Statistical graphical models have now been applied by both statisticians and scientists in a vast variety of domains and their methodology, although still refined, is well established \citep{Aguilera2011,Jordan2004,Korb2003,Oliver1990,Smith2010,Uusitalo2007}. However, as the nuclear emergency management example in the following section highlights, many areas of science still have to recognise the importance and the need for a complete uncertainty handling. The goal of deducing objective scientific conclusions, which does not allow for uncertainty claims, still permeates scientific reasoning \citep[see for example the recent discussion in][concerning the continuous development of higher-resolution simulators for predicting climate change] {Rougier2015}. Symbolically, in \citet{Carter2006} uncertainty is said to be discomforting to the parties involved in decision making, whilst in \citet{Ahlbrecht1997} uncertainty is even referred to as disconcerting for DMs. \citet{Carter2006} further highlights the far too limited perspective on uncertainty in the ESs developed. In Chapter \ref{chapter4} we show how current DSSs can lead DMs to irrational behaviour due to the lack of complete probability propagations. 
     
\section{An Overview of Nuclear Emergency Management}
\label{sec:nuclear}
In 1986 an explosion at one of the  reactors of the Chernobyl nuclear power plant released a radioactive plume into the environment contaminating large areas of the former Soviet Union. To protect people and food stocks, measures were taken by the governments of the affected countries. Different and often conflicting responses were further taken by many European countries after the accident, confusing the  public opinion and leading to an ineffective implementation of countermeasures \citep{Papamichail2013, Walle2008}. It was therefore recognised the need of a comprehensive response to nuclear emergencies within the European community. The way to achieve such coherent response was identified to be the development of a common comprehensive DSS for off-site emergency management. Several institutes in Europe then started the development of the Real-time On-line DecisiOn Support system (RODOS) for nuclear emergencies, which would provide consistent predictions unperturbed by national boundaries \citep{Ehrhardt1993}. We note here that other DSSs were built by different initiatives during the following years, notably ARGOS \citep{Hoe2003} and MOIRA \citep{Monte2009}. Here we focus our attention on the RODOS system only, which embodies in its architecture the typical features of a nuclear emergency. 

Alongside the development of RODOS, in the early 1990s the International Chernobyl Project aimed at exploring the factors that drove decision making on protective measures after the Chernobyl accident. Since many different parties and institutions were involved in the decision making process at the time, the study was organised in five decision conferences (see Chapter \ref{sec:decconf}) (one for each of the affected countries - Belarus, Russia and Ukraine - and two at all-Union level) where simple MultiCriteria Decision Analysis (MCDA) models were used to explore the preferences and the beliefs of the different parties. The analyses performed during these meetings clearly showed that not only radiation related health effects and use of resources were relevant factors, as usually conceived by standard cost-benefit analyses for radiation protection decisions, but also the effects on the health of stress and the political acceptability of the countermeasures taken. Note that MCDA methods are based on subjective judgements of the DMs and for this reason had not been used beforehand in emergency management \citep{Papamichail2013}, confirming the discomfort of scientists with non-objective analyses mentioned above. The successful recognition by the International Chernobyl Project of additional factors that drove decision making further highlights the necessity of using subjective techniques in decision making.

Therefore, it was decided that MCDA methods had to be included in any operational DSS for nuclear emergency recover as RODOS. Such a DSS would then combine scientific knowledge about the likelihood of different events with the value judgements about these  to rank different agreed available policies and both facilitate the exploration and create a deeper understanding of the problem at hand. The conceptual architecture of the DSS RODOS itself mirrors the above description \citep{Caminada2000}, since the system is composed by the following three subsystems:
\begin{itemize}
\item the Analysing SubsYstem (ASY) processes incoming data and forecasts the location and the amount of contamination through time;
\item the  Countermeasure SubsYstem (CSY) suggests countermeasures, verifies their feasibility and computes their benefit according to several criteria;
\item the Evaluating SubsYstem (ESY) ranks policies according to their potential overall benefits and provides explanations  for the reasons of such a ranking.   
\end{itemize} 
Figure \ref{fig:fromBri} summarises how the three subsystems are operationally linked in RODOS. As shown on the left of the diagram, the output of the ASY, consisting of both the likelihood of various events and the forecasts of contamination, are used as input for the CSY. Given these forecasts, the CSY simulates the effects of the available decisions. The results of these simulations are then used by the ESY subsystem to produce a rating of each available countermeasure. We now look into more details into each of these subsystems.

\begin{figure*}
\begin{center}
\begin{tikzpicture}
[ man/.style={rectangle, rounded corners,draw=black!80,top color=white, bottom color=blue!50, align=center, node distance=2.5cm, inner sep=0pt, minimum height=1.6cm, minimum width=2.8cm,  thick,scale=0.9},
 man1/.style={rectangle, rounded corners,draw=black!80,top color=white, bottom color=blue!50, align=center, node distance=5cm, inner sep=1pt, minimum height=1.6cm, minimum width=5.6cm, font=\small, thick, },]
\node[man] (A) {\textbf{ASY}\\ `Analysing\\ subsystem'};
\node[man] (B) [below of=A] {\textbf{CSY}\\ `Countermeasure\\ subsystem'};
\node[man] (C) [below of=B] {\textbf{ESY}\\ `Evaluation\\ subsystem'};
\node[man1](D)[right of=A]{Display of contamination data.\\ Analysis and forecast of the \\ development of the contamination\\ based on data and \\ models' outputs};
\node[man1](E)[right of=B]{Simulation of the effects of\\ the available countermeasures,\\ judgement  of their attainability and \\ evaluation of the consequences \\ of each countermeasure.};
\node[man1](F)[right of=C]{Evaluation and rating of \\ the possible countermeasures by \\ considering their positive and  \\ negative sides, together with\\ explanations of the ratings.};
\node[single arrow, shape border rotate =270, draw=black!80,align=center, node distance=4cm,top color=white, bottom color=blue!50, thick] (G) at (10.5,-1.2) {\textbf{Emergency Actions:} \\ Evacuation;\\ Sheltering;\\ Protective measures;\\  \\ \textbf{Long term measures:}  \\ Resettlement; \\ Purification; \\ Agricultural measures; };
\draw [->,line width=0.5mm](A) -- (B);
\draw [->, line width=0.5mm](B) -- (C);
\draw[-, line width=0.5mm] (A)--(D);
\draw[-, line width=0.5mm] (B)--(E);
\draw[-, line width=0.5mm] (C)--(F);
\end{tikzpicture}
\caption{Conceptual structure of RODOS from \citet{Leonelli2013} and after \cite{raskob2009}. The left column lists the subsystems, the central one describes the functionalities of each of these and the right one summarizes potential countermeasure both in the short and in the long term.}
\label{fig:fromBri}
\end{center}
\end{figure*} 

MCDA techniques were included into both the CSY and the ESY components to evaluate and rank potential countermeasures. It is important to note here the relevance of the explanation module within the ESY (as expressed in the bottom-central box of Figure \ref{fig:fromBri}). Empirical research has shown that DMs do not accept the suggestions of a system which does not provide a rationale for the outputs it produces, even if the system delivers accurate results  \citep{Papamichail2013}. Furthermore, as extensively discussed in \citet{French2009}, the ultimate objective of any decision analysis is not in simply choosing a decision which is considered to be optimal according to certain criteria, but more importantly in developing a deeper understanding of the values and the uncertainties of the problem studied. These insights may then lead to an evolution of the DMs' judgements and possibly to a revision of the whole model. This process is often called requisite modelling \citep{Phillips1984}. This idea was effectively included in the initial aims of both the development of RODOS and the International Chernobyl Project. Therefore RODOS includes a variety of features to justify its outputs, as for example a natural language report generator to explain the ranking of the policies \citep{Papamichail2003}, sensitivity analysis graphs and their interpretations \citep{Papamichail2005}.

The ASY subsystem is made of many different \textit{modules} (or component DSSs), each providing estimates and forecasts for a different aspect of the emergency as stated in the top central box of Figure \ref{fig:fromBri}. For instance, one of these modules concerns the workings of the source term estimating the likelihood of a release of contamination from the plant. Another one includes atmospheric diffusion models describing the spread of the contamination. Additional modules model the effect of this spread might have because of the exposure of  humans, animals and plants. Although the ASY modules are capable of working independently, in a comprehensive emergency management these are networked together in the sense that the outputs of some modules are used as inputs for others. Another important element to highlight from the above description is that the domains the ASY modules aim at describing are particularly heterogeneous and therefore require knowledge about a variety of different disciplines. In Figure \ref{networkino}, from \citet{Leonelli2013},  a plausible network of modules for use of a nuclear DSS is presented. Each vertex of the network corresponds to a module and two modules are connected by an arc if the outputs of the parent node are used as inputs for the child node (see Appendix \ref{appendixB} for an introduction to graph theory). The modules corresponding to the vertices of the network in Figure \ref{networkino} cover the main aspects of a nuclear emergency, as for example the overall workings of a nuclear power plant (Power plant and source term nodes), the spread of contamination (Air and Water dispersal and contamination) and the consequences the accident (Human health, Costs and Political effects). The nodes are grouped in such a way that vertices with the same color represent modules concerning the same domain of expertise. Specifically, the grey vertices are concerned with engineering issues; the green ones with the environment; the blue ones with biological consequences; the brown, red and yellow ones with the political, medical and economical outcomes, respectively. Furthermore, the edge set of the network in Figure \ref{networkino} describes plausible input/output relationships between the modules. So, for instance, the Deposition module uses as input only the outputs of the Water and Air dispersal modules, whilst Human absorption depends on Water dispersal, Animal absorption and Deposition since these are the main factors through which human can get in touch with the contamination. 
\begin{figure*}
\begin{center}
\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=1.5cm,
                    semithick]
 \tikzstyle{every state}=[fill=white,draw,text=black, shape=rectangle, rounded corners,every text node part/.style={align=center}]
  \node[state]  (A)      [fill=black!20, draw=black!100, text=black]              {Power \\ plant};
  \node[state]         (B) [right = of A, draw=green!100, fill=green!20] {Water \\ dispersal};
   \node[state] (C) [draw=blue!100,  fill=blue!20,  right = of B]{Human \\ absorption};
\node[state] (D) [below of=A, fill=black!20, draw=black!100, text=black ]{Source \\  term};
\node[state](E)[below of=D, draw=green!100, fill=green!20]{Air \\ dispersal};
\node[state](F)[below of=B, draw=green!100, fill=green!20]{Deposition};
\node[state](H)[below of=F, draw=brown!100, fill=brown!20]{Political \\ effects};
\node[state] (L)[draw=blue!100,  fill=blue!20, text=black, below of =  C]{Animal \\ absorption};
\node[state](I)[below of=L, fill=yellow!20, draw=yellow!100]{Costs};
\node[state](G)[draw=red!100, fill=red!20, right=1cm of L]{Human \\  health};
\path (A) edge (D)
        (D) edge (B)
             edge (E)
         (B) edge (C)
              edge (L)
             edge (F)
          (E) edge (H)
               edge (F)
           (L) edge (C)
         (C) edge (G)
         (F) edge (L)
             edge (I)
             edge (C)
          (L) edge (I)
         (G) edge (I)
          (I) edge (H);
\end{tikzpicture}
\end{center}
\caption{Plausible network for the modules of a nuclear decision support system. \label{networkino}}
\end{figure*} 

Each of the modules of the ASY comprises a set of methodologies, either deterministic or stochastic, to perform the task they were designed for. As an example, \citet{Turner1994} lists dozens of different atmospheric dispersion models that have been applied to different domains and systems. From the very early stages of the development of RODOS it was recognised \citep[after considerable debate, as noted in][]{Smith1997} that stochastic, and more specifically, Bayesian inferential methodologies should be used in such a nuclear DSS to assimilate, combine and represent uncertainties. \citet{Smith1997} and our discussion in Section \ref{sec:early} extensively argued why it is reasonable to use this representation of uncertainty. Therefore, different Bayesian models have been developed for the different modules, as for example a BN for the workings of the source term \citep{Caminada2000}, a dynamic random forest for the atmospheric dispersion \citep{Smith1997} and a dynamic spatial model for the deposition module \citep{De2011}.  

It is also important to note here that in theory it could be possible for the ASY to consist of a single big module which models the whole domain of nuclear emergency management. However, the provision of the system to be used across all the European countries required the software to support the integration of external programs developed by national research institutes of the many involved countries. Therefore, the ASY had to be structured in this modular form, as a network of sub-models concerning the different elements of the emergency.

The description of the RODOS system for nuclear emergency management has highlighted the complexity of the domains that current  DSSs aim at describing. The main points to inherit from this section are the following:
\begin{itemize}
\item inference and forecasting need to be distributed among the different modules within the DSS;
\item the judgements and beliefs of different individual with different expertise need to be included in the inferential process;
\item computations need to be fast to allow for real-time decision making in case of an emergency;
\item MCDA techniques need to be included to reveal the true values of the DMs.
\end{itemize}

It is important to underline the scientific relevance of a project like the development of RODOS. Fortunately, although the consequences of a nuclear accident are and are perceived as severe and far-reaching,  the probability of occurrence of these is extremely low and RODOS is likely not to be used for actual emergency management \citep{Geldermann2009}.\footnote{\citet{Walle2008} noted that such a system could be actually used for different types of nuclear threats, as for example dirty bombs, although this type of aid is not publicly stated in the mission of RODOS.} At the same time, this implies that data and knowledge about this type of emergencies is scarce. The process of the construction of RODOS has actually deepened the understanding of both the values of potential DMs and the possible evolutions of the emergency. As noted in \citet{Papamichail2013}, nuclear emergency management has been at the forefront of both  stakeholder engagement and the use of decision conferencing, demonstrating the benefits of these techniques. Nowadays RODOS is not only used as an incommensurable educational tool for training personnel through exercises of scenario analysis, but also to highlight the areas in which current emergency management plans may not be adequate. \citet{Gering2013} reported a study where RODOS was used to simulate emergencies with features similar to the recent outworkings of the Fukushima nuclear plant and showed that current methodologies have several major problems. 

\section{Current Probabilistic Expert Systems}
\label{sec:current}
The complexity of the models that are currently built to tackle real applications, as the nuclear one, is increasing radically. The decomposition into local distributions that standard graphical models offer is not sufficient any more to both clearly depict the situation under study and allow for fast computations. Within the statistical graphical community, this was first recognised in \citet{Mahoney1996} for modelling military problems. The authors highlighted the need of an additional intermediate level of decomposition which breaks down the problem into a set of coupled components, both semantically and formally separable. Semantic separability implies that the component is meaningful to the user of the model, whilst formal separability means that the different components can be re-aggregated into a consistent probability model. This intermediate decomposition exactly corresponds to the division of the ASY component into networked modules within the RODOS system as in Figure \ref{networkino} and is indeed called in \citet{Mahoney1996} \textit{modularisation}.

\citet{Mahoney1996} referred to two attempts in the literature to create this intermediate level of modelling, namely similarity networks \citep{Heckerman1990} and  multi-sectioned BNs \citep{Xiang2002,Xiang2011}.  However, since both these attempts do not allow for enough modelling flexibility, they pointed towards the use of object oriented techniques in probabilistic modelling, similar to the ones used in programming languages. The authors noticed, as further stressed in \citet{Johnson2012}, that the object oriented paradigm provides features to simplify the modelling task in complex situations.  Specifically:
\begin{itemize}
\item \textbf{abstraction}/\textbf{encapsulation}: this means that some information is hidden to the user and its access is allowed only via a predefined interface. Modifications within these interfaces do not affect other parts of the system;
\item \textbf{modularisation}/\textbf{reuse}: the system is composed of a set of loosely connected units, which, if the interfaces are held fixed, can be changed without having to rebuild the whole model.
\end{itemize} 
These features are embedded in the IDSS methodology we introduce in this thesis and, by recalling the description of the nuclear DSS RODOS, are required if we are to develop support systems to be used in practice. 

The object oriented route for probabilistic graphical models then started with the development of Object Oriented Bayesian Networks (OOBNs) \citep{Koller97} and, concerning the modelling of complex situations, then continued in two main streams of research. The first one aimed at integrating first-order logic with Bayesian probability theory and culminated with the definition of multi-entity BNs \citep{Laskey2008, Laskey2009}. These can be represented as a collection MFrags \citep{Laskey1997}, which can be thought of as OOBNs with root nodes having known values. The other strand of research discusses the use of OOBNs as an integrating tool and introduced the concept of integrating BNs \citep{Johnson2012a}. An integrating BN can be thought of as a large OOBN where different probabilities are elicited by different groups of experts. These are a special case of IDSSs, but still represent an important step forward to the representation and elicitation of complex probabilistic models. These have been successfully applied to a variety of domains \citep{Johnson2013, Johnson2014,Mortera2013}.   

A completely different route from the object oriented paradigm in ESs has been proposed in \citet{Goldstein96}, which suggested the use of Bayes linear methodologies not requiring the specification of a full prior distribution \citep[see e.g.][]{Goldstein2007}. This approach simplifies both the computation and the elicitation burden, but does not provide in itself a viable alternative for the modelling of complex situations as the nuclear emergency management case described above.

Although all the above models can be used to support management decisions as noted in \citet{Johnson2014}, these do not include any formal representation of both the available decision space and the preferences of the DM, as required in the nuclear emergency management example. Influence Diagrams (IDs) are a class of graphical models  representing random variables, utilities and decisions \citep[see e.g.][and Section \ref{sec:id}]{Bielza2011,Howard2005,Jensen2013}. Of critical important is to  note that the literature about IDs does not provide many insights on the use of these models for the representation and modelling of complex situations. The main focus of ID's research has been on the improvement of the speed computations, either exact or approximated. Thus, although IDs include both decision and utilities, these  do not possess the expressive power of, for example, integrating BNs for the representation of current applied problems.

Before concluding this section, we note that the description of the nuclear emergency management domain highlighted the geographic nature of many problems that DMs have to deal with in practice. On one hand, this simply means that the dimensionality of the overall problem grows since each variable of the large system might be recorded and observed at different locations in space. On the other, it also raises issues specific of geographic modelling and concerning the use of geographic information systems in probabilistic models \citep{Stassopoulou1998}. Although we do not deal specifically with these issues, we recognise their importance in many applications and we note that there are now methods customised for the integration of geographic information systems with graphical models \citep{Laskey2010, Johnson2012}. However, in Section \ref{sec:exalgo} we present two examples of how a geographic component can be included into an IDSS in the simplest possible case.

\section{Decision Support Systems for the XXI Century}
\label{sec:decision}
Although the technology  reviewed in the previous section represents a big step forward in the modelling of complex issues, we note here that these methodologies still do not address many of the features of classes of problems as the nuclear emergency management of Section \ref{sec:nuclear}. 

First, because of the underlying OOBN assumption, most of the methods above assume that each submodel is a graphical one. This is a restrictive assumption and, as we saw, many statistical models, not necessarily graphical, have been already developed for some of the ASY components of RODOS. Furthermore some of the modules in use often are not probabilistic: this is the case for example of big simulators that model climate change. The technology of \textit{emulators} \citep[][and Section \ref{sec:emu}]{Kennedy2001, OHagan2006} can then be used  to introduce a probabilistic distribution over the outputs of such simulators. 

Second, RODOS implemented MCDA techniques to perform a formal decision analysis. Many current statistical ESs do not allow for such outputs and in general provide only probabilistic beliefs on a set of goal variables. Therefore, there is a need for new methods to be implemented in DSSs that have the power of performing MCDAs. In RODOS this was based on value functions. We argue here though that for current DSSs this is not sufficient and that multiattribute utility theory, enabling a full uncertainty handling, needs to be used as a representation of the DMs' preferences.      

Third, in such domains decision making is not usually the responsibility of a single individual but rather of groups. Decision centres will have the accountability and the responsibility of choosing a course of action and their judgements will be supported by best experts' knowledge. Therefore, DSSs need  to provide both a theoretical framework allowing for such a collaborative purpose and the technology  to support prescriptive team decision making.   

Lastly, in order for this to be feasible in practice, both probabilistic inferences and preferential modelling need to be distributed, as in the ASY, ESY, CSY structure of a system like RODOS. Therefore, the distributed nature of, for example, an integrating BN needs to embellished with a formal preferential analysis, which entertains the same distributed nature, both formally and semantically. 

It is therefore fundamental to develop a framework with the above features in order to properly support DMs in real current applications. As remarked by \citet{Mahoney1996}, the distributed nature of such a methodology is vital, since the following benefits would follow:
\begin{itemize}
\item computational tractability;
\item comprehensibility;
\item feasibility of testing.
\end{itemize}
Computational tractability derives from the local computation structure associated to distributed systems \citep[widely studied in machine learning, see e.g.][]{Peteiro2013,Rodriguez2011}. Distributed systems are more comprehensible since the overall outputs can be traced back to each subsytem's outputs, providing much clearer justifications of the delivered estimates. Finally, feasibility of testing follows since each subsystem can be more straightforwardly tested and potentially upgraded than the whole system at once.  In the following we highlight how the IDSS methodology we introduce here entertains such features.

As with the motivations that lead to the inception of graphical modelling techniques, we can notice that distributivity in complex systems aims at breaking down   a huge problem into ones of smaller dimension. In \citet{Spiegelhalter1993} such a modelling approach was referred to as \textit{divide-and-conquer}. The methodology of IDSSs uses the same idea to simplify decision analyses in highly multivariate and heterogeneous problems. We note here that such an approach is commonly used in a variety of domains and subjects, as for example in composite likelihood methods \citep{Varin2011}, Markov chain Monte Carlo  schemes \citep{Lindsten2014} and parallel computing \citep{Chandy1998}.   

\section{Contributions of the Thesis}
\label{sec:contributions}
In this thesis we develop a methodology that addresses the gaps of current ESs we listed in Section \ref{sec:decision} to model complex domains. We call our methodology an \textbf{IDSS}, which embeds a formal distributed Bayesian decision analysis combining the beliefs of different of groups of experts. Throughout the thesis we specify the conditions enabling such an integration in a variety of frameworks and discuss the advantages of this methodology. We then provide a toolkit of methods for inference and decision making in an IDSS by, for instance, developing propagation algorithms and symbolic methodologies.

From a more specific/domain-based viewpoint, the results in this thesis extend current methods on a variety of aspects:
\begin{itemize}
\item in Chapter \ref{chapter3} we extend standard independence notions over the parameter vectors of a variety of graphical models \citep[see e.g.][]{Spiegelhalter1990,Dawid1993, Freeman2011} enabling distributed multi-expert inferences in IDSSs;
\item there are now several rules to combine expert judgement in the literature \citep[see e.g.][]{French2011}. Our work extends such rules for complex multivariate domains where the overall probability distribution can be described by means of a graphical model (see e.g. Propositions \ref{prop:combi} and \ref{prop:dyncombi});
\item a new concept of statistical causality tailored to the needs of an IDSS is defined in Section \ref{sec:idsscaus}. We are able to show that the standard definition of causality of \citet{Pearl2000} represents a special case of our definition;
\item we introduce a new class of utility factorisations in Section \ref{sec:comput} customised to the needs of an IDSS, allowing for a distributed computation of Bayesian expected utilities in the multi-expert domains we address;
\item we  introduce in Section \ref{sec:algorithms} new utility-based propagation algorithms for the distributed computation of expected utility scores in IDSSs. Some of the current evaluation algorithms of decisional structures can be seen as special cases of the ones we define here;
\item we deduce new recursions for the computations of moments of functions over the vertices of an agreed graphical model, generalising the ones of \citet{Cowell1999a} and \citet{Nilsson2001};
\item by studying decision making in an IDSS from an algebraic perspective, we identify minimal sets of independence statements assuring the system provides rational decision support. This recognition leads us to define in Section \ref{sec:momind} new types of independence tailored to the needs of an IDSS; 
\item we develop in Section \ref{sec:short} new symbolic approaches to decision making in different frameworks, which extends current symbolic methods for probabilistic reasoning in graphical models \citep[see e.g.][]{Castillo1997, Darwiche2003}.
\end{itemize}
More detailed explanations of how our results generalise current methodologies can be found in the following chapters. 

In this thesis we almost exclusively focus on the technical conditions that guarantee the existence of an IDSS. In order to concisely illustrate this methodology, our examples necessarily need to be small-dimensional. However, as we discuss more extensively in the following chapters, our methods would scale up to larger real-world examples because of the distributed nature of IDSSs.

The material of this thesis has appeared/will appear in seven papers I have co-authored with my supervisor Jim Smith and other collaborators. Additional details about these papers can be found in the Declaration on page \pageref{declaration}. 
\section{Structure of the Thesis}
\label{sec:structure}
Having extensively discussed the need for an IDSS and reviewed other statistical approaches to model complex domains in this first chapter, in Chapter \ref{chapter2} we survey classical Bayesian decision analysis methods. We then discuss  standard Bayesian reasoning and the Subjective Expected Utility (SEU) methodology for decision making. We introduce a variety of probabilistic, utility and decision models. We further survey issues associated to group decision making and the use of expert judgement. 

In Chapter \ref{chapter3} we introduce IDSSs and a set of axioms that can guarantee their existence. We then discuss what makes a \lq{g}ood' IDSS  and generic conditions that can ensure a good IDSS both a priori and after the introduction of both observational and experimental data.  We then show that many of the statistical models introduced in Chapter \ref{chapter2} can be used as an underlying probabilistic framework for an IDSS and discuss the conditions that these need to entertain. 

We then consider in Chapter \ref{chapter4} a large class of IDSSs based on flexible probability and utility models. For this class we develop distributed utility-based propagation algorithms that allow for the exact computation of expected utility scores from the outputs of the individual modules of the IDSS. We then exemplify the methodology at the end of the chapter in a variety of domains. 

The expressions used by the IDSS to rank the available policies are often polynomial functions of the outputs of the component DSSs. This recognition lead us to analyse IDSSs in Chapter \ref{chapter5} from an algebraic viewpoint and to define independence concepts following from the polynomial relationships existing between these outputs. We then introduce symbolic techniques for particular statistical models in IDSSs, which are intimately linked with algebraic analyses. 

We conclude the thesis in Chapter \ref{chapter6}, where we summarise the main results of the thesis and discuss possible extensions of the methods developed in the thesis. 

The thesis also include 5 appendices. In Appendix \ref{appendixA} we collect longer proofs. Appendix \ref{appendixB} introduces the required terminology of graph theory. Appendix \ref{appendixE} reviews basic statistical distributional theory and standard Bayesian models. Appendix \ref{appendixC} consists of basic definitions of polynomial algebra. In Appendix \ref{appendixD} we report our computer algebra code to implement the methods we introduce in Section \ref{sec:symbolic}. 