% Chapter 1

\chapter{Introduction} % Main chapter title

\label{chapter1} % For referencing the chapter elsewhere, use \ref{Chapter1} 

\lhead{Chapter 1. \emph{Introduction}} % This is for the header on each page - perhaps a shortened title

%----------------------------------------------------------------------------------------
The activity of decision making pervades everyday life of human beings. For instance, we choose for example what type of food to have for dinner or what road to take to go to work. However, not all types of decisions that we have to commit to might be as straightforward as the ones above. For example, deciding whether or not to shut down a nuclear source term due to a malfunctioning on site or committing to a policy concerning climate change to reduce CO\textsubscript{2} emissions at world level requires an accurate reflection about the consequences of the available courses of action. In these situations the \gls{DM} - that here will be the individual who has the responsibility, accountability and authority to determine a decision and possibly implement it -  needs to make choices in complex and evolving environments, described through multiple and interdependent processes with many associated measurements \citep{Bennet2009}. 

Empirical and behavioural research has shown that humans exhibit, even in very simple situations, a high number of inconsistencies when making decisions  \citep{Tversky1974}. Our actions can often be said to be \textit{irrational} - according to some canons of rationality that we will discuss in more details in the following. Additional research has further shown however that the number of fallacies \glspl{DM} may incur in can greatly decrease if they are properly supported during the decision making process \citep[see e.g.][]{Bhandari2008}. Thinking about our everyday life, when we are faced with a decision problem involving elements we are not familiar with, we often seek for the help of a person with the relative expertise in the appropriate field. For our purposes, we will say that an individual has expertise, and therefore is an \textit{expert}, if he/she has a comprehensive and authoritative knowledge of a specific field, not possessed by many people \citep{Caley2014}. 

\glspl{ES}, usually computer-based, aim at simulating the reasoning of experts and therefore at providing the required support to \glspl{DM} by codifying expert knowledge. These usually use artificial intelligence techniques to process information, learn, reason and make predictions, thus enhancing the process of decision making. Within the information systems' literature, \glspl{ES} are considered as a special class of \textbf{\glspl{DSS}}, usually called intelligent \glspl{DSS} \citep{Marakas2003}. There is a large number of definitions of what a \gls{DSS} is. Here we follow \citet{French2009} saying that a ``\gls{DSS} is a computer-based system that supports the decision-making process, helping \glspl{DM} to understand the problem before them and to form and explore the implications of their judgements, and hence to make a decision upon understanding''. Both \glspl{DSS} and \glspl{ES} can provide great benefits to \glspl{DM} since they can combine the knowledge of several experts into a reusable tool that quickly processes information and makes inferences. For the purposes of this thesis we will use the two terms interchangeably, but we note that the term \gls{ES} is more used within the statistical community, whilst \gls{DSS} appears more frequently in the information systems' literature.

Although \glspl{DSS} and \glspl{ES} have now been developed and used in practice in a variety of domains, we argue in this thesis that  \glspl{DM} can only be properly supported in \textit{complex} current situations by an \textbf{\gls{IDSS}} \citep{Leonelli2015,Smith2015}, which networks together different \glspl{DSS} into a unique coherent supporting tool. Here briefly we notice that this is true mainly for two reasons. First, current applications, as for example nuclear emergency management, require knowledge on a variety of different domains, which can be difficult to synthesize into a unique system. Second, the network structure connecting different \glspl{DSS} can provide the basis for both distributed computations and reasoning, increasing both the comprehensibility of the analyses performed and the speed of computation, so that the system can be used in real-time. 

In order to support more strongly our statements, and therefore highlight both the relevance and the contributions of this thesis, we need to provide a short history of the development of \glspl{ES} within the statistical literature. In Section \ref{sec:early} we describe early \glspl{ES} in use in the last century. This will also lead us to talk about the treatment of uncertainty in \glspl{ES} and more generally in science. Before discussing more recent \gls{DSS} technologies, we will take a little digression in Section \ref{sec:nuclear} to illustrate the use of \glspl{ES} and \glspl{DSS} for nuclear emergency management, which will further shed light on both some of the subsequent developments of these systems and the relevance of our results. In Section \ref{sec:current} we then describe modern statistical \glspl{DSS} and discuss how these address the needs of current applications as nuclear emergency  management. Section \ref{sec:decision} highlights the need for and the main features of \glspl{IDSS}  by noticing the flaws of current \glspl{DSS} in properly supporting the decision making process in complex domains. We then conclude the chapter by specifying the contributions and the structure of the thesis in Sections \ref{sec:contributions} and \ref{sec:structure} respectively. 
    
\section{Early Probabilistic Expert Systems}
\label{sec:early}
At their inception, \glspl{ES} were only able to model deterministic domains. Their knowledge base - comprising facts about the world and an inference engine  -  consisted of a set of deterministic rules and, for this reason, such deterministic systems are often referred to as rule-based \glspl{ES}. \citet{Castillo1997b}, whilst including an overview of rule-based systems and their domains of application, recognized that the deterministic assumption is too restrictive in most, if not all, of the cases. As the complexity of the problems addressed by \glspl{ES} increased, a slow recognition of the need of introducing measures of uncertainty began to be appreciated. Uncertainty, as firmly stated by \citet{French95}, is part of any decision analysis, arising, among the others, from physical randomness, imprecision of meaning and various estimates, and therefore needs to be properly addressed. 

However at first, probabilistic reasoning was not considered as a viable option for uncertainty modelling in \glspl{ES} for a variety of reason:
\begin{itemize}
\item probability theory was thought as epistemologically inadequate in this context;
\item it required the specification of an infeasible number of probabilities;
\item even if a \gls{DM} were able to somehow elicit these probabilities, the appropriate computations would still be infeasible. 
\end{itemize}
For these reasons different approaches to the representation of uncertainty were followed, as for example non-monotonic and fuzzy logic, certainty factors and Dempster-Shafer belief functions \citep[see e.g.][respectively]{Gabbay1985, Klir1995, Buchanan1984, Shafer1976}. However neither of these has been able to provide a sound and coherent methodology for uncertainty handling. Only probability has proven to be able to clearly represent uncertainty, as strongly asserted by, among the others, \citet{Lindley1979} who states ``the only satisfactory representation of uncertainty is probability ... [and] alternative descriptions of uncertainty are unnecessary''.

Around the 1980s solutions to the three main critics about the use of probability in \glspl{ES} began to appear, which allowed for a wider applicability of probabilistic \glspl{ES}. Firstly at that time the frequentist interpretation of probability was mostly widespread within the statistical community. This school of thought defines probability as the long-run frequency of occurrence in repeated events: probability is an intrinsic property of the system being observed. In some sense this approach has a persuasive appearance of objectivity, which has been pursued throughout history by the physical sciences and in more recent times by the social sciences, striving to be recognized as nonsubjective. Clearly, this definition of probability does not fit the process of supporting \glspl{DM}, since decision situations are unique and human interventions change the observed system. In addition, the frequentist approach does not lead straightforwardly to methods for providing predictions and measures of uncertainty about these. The subjective Bayesian definition of probability, which defines it as the degree of belief about the state of the world under consideration by the observer, or in a decision making context, by the \gls{DM}, naturally provides an interpretation of probability that can be used for uncertainty modelling in \glspl{ES}. This is because within the Bayesian framework probability is not any more an intrinsic property of the system, but belongs to the \gls{DM} and represents her own beliefs about it. 

Secondly, the axiomatization of conditional independence proposed by \citet{Dawid1979} provided a methodology to break down a complex problem into smaller ones, allowing for a large dimensional joint probability to be written as a product of local distributions of smaller dimension. Although conditional independence found an important application in probability theory, it is important to remark that it is a generic tertiary operator that therefore can be used in different domains. In statistics the notion of conditional independence then led to the definition of various classes of statistical graphical models, as for example \glspl{MN} and \glspl{BN} \citep[see, among the others, ][and Sections \ref{sec:BN} and \ref{sec:UG}]{Lauritzen1996a,Pearl1988a}, which exploiting conditional independences, represent the qualitative structure of a multivariate random vector through a graph. We will discuss in more details graphical models in Chapter \ref{chapter2}, but it is important to note here that the number of probabilities to be determined decreases dramatically under the assumption of a graphical model, the rate depending on the connectivity of the graph. 

Lastly, although the Bayesian paradigm was able to provide an epistemologically valid representation of uncertainty for decision support, and graphical modelling allowed to define these probabilities in many real cases, the actual probabilistic computations would be still infeasible without further technological advances. A key element here was the use of triangulation techniques that were already well-known in the relational databases literature \citep{Spiegelhalter1993}. In a nutshell, triangulation clusters some of the nodes into a single entity allowing for faster computations and propagations of evidences. At the same time Bayesian stochastic numerical techniques started to slowly appeared, which allowed for the computations of at least approximated probabilities in complex systems \citep[see e.g.][]{Gilks1996}. These are now well established and in practice often faster and more reliable than standard frequentist asymptotic methods.

Graphical models have now been applied by both statisticians and scientists in a vast variety of domains and their methodology, although still refined, is well established \citep{Aguilera2011,Jordan2004,Korb2003,Oliver1990,Smith2010,Uusitalo2007}. However, as the nuclear emergency management example in the following section will discuss, many areas of science still have to recognize the importance and the need of a complete uncertainty handling. The goal of deducing objective scientific conclusions, which does not allow for uncertainty claims, still permeates scientific reasoning: see for example the recent discussion in \citet{Rougier2015} concerning the continuous development of higher-resolution simulators for predicting climate change. Symbolically, in \citet{Carter2006} uncertainty is said to be discomforting to the parties involved in decision making, whilst in \citet{Ahlbrecht1997} uncertainty is even referred as disconcerting for \glspl{DM}. \citet{Carter2006} further highlights the far too limited perspective on uncertainty in the \glspl{ES} developed. It is therefore relevant to underline the need for full uncertainty handling and in Chapter \ref{chapter4} we will show how current \glspl{DSS} can lead \glspl{DM} to irrational behaviour due to the lack complete probability propagations. \todo{First forward reference to recall.}
     
\section{An Overview of Nuclear Emergency Management}
\label{sec:nuclear}
In 1986 an explosion at one of the  reactors of the Chernobyl nuclear power plant released a radioactive plume into the environment contaminating large areas of the former Soviet Union. To protect people and food stocks, measures were taken by the governments of the affected countries. Different and often conflicting responses were further taken by different European countries after the accident, confusing the  public opinion and leading to ineffective implementation of countermeasures \citep{Papamichail2013, Walle2008}. It was therefore recognized the need of a comprehensive response to nuclear emergencies within the European community. The way to achieve such coherent response was identified to be the development of a common comprehensive \gls{DSS} for off-site emergency management. Several institutes throughout Europe then started the development of the \gls{RODOS} for nuclear emergencies, which would provide consistent predictions unperturbed by national boundaries \citep{Ehrhardt1993}. We note here that other \glspl{DSS} were built by different initiatives during the following years, notably ARGOS \citep{Hoe2003} and MOIRA \citep{Monte2009}. For the purposes of the thesis, we focus our attention on the \gls{RODOS} system only, which embodies in its architecture the typical features of a nuclear emergency. 

Alongside the development of \gls{RODOS}, in the early 90s the International Chernobyl Project aimed at exploring the factors that drove decision making on protective measures after the Chernobyl accident. Since many different parties and institutions were involved in the decision making process at the time, the study was organized in five decision conferences (see Chapter \ref{sec:decconf}) (one for each of the affected countries - Belarus, Russia and Ukraine - and two at all-Union level) where simple \gls{MCDA} models were used to explore the preferences and the beliefs of the different parties. The analyses performed during these meetings clearly showed that not only radiation related health effects and use of resources were relevant factors, as usually conceived by standard cost-benefit analyses for radiation protection decisions, but also the effects on the health of stress and the political acceptability of the countermeasures taken. Note that \gls{MCDA} methods are based on subjective judgements of the \glspl{DM} and for this reason had not been used beforehand in emergency management \citep{Papamichail2013}, confirming the discomfort of scientists with non-objective analyses mentioned above. The successful recognition by the International Chernobyl Project of additional factors that drove decision making further shows the necessity of using subjective techniques in decision making.

Therefore, it was decided that \gls{MCDA} methods had to be included in any operational \gls{DSS} for nuclear emergency recover as \gls{RODOS}. Such a \gls{DSS} would then combine scientific knowledge about the likelihood of different events with the value judgements about these  to rank different agreed available policies and both facilitate the exploration and create a deeper understanding of the problem at hand. The conceptual architecture of the \gls{DSS} \gls{RODOS} itself mirrors the above description \citep{Caminada2000}, since the system is composed by the following three subsystems:
\begin{itemize}
\item the \gls{ASY} processes incoming data and forecasts the location and the amount of contamination through time;
\item the \gls{CSY} suggests countermeasures, verifies their feasibility and computes their benefit according to several criteria;
\item the \gls{ESY} ranks policies according to their potential overall benefits and provides explanations  for the reasons of such ranking.   
\end{itemize} 
Figure \ref{fig:fromBri} summarizes how the three subsystems are operationally linked in \gls{RODOS}. We now look into more details into each of these subsystems.

\begin{figure*}
\begin{center}
\begin{tikzpicture}
[ man/.style={rectangle, rounded corners,draw=black!80,top color=white, bottom color=blue!50, align=center, node distance=2.5cm, inner sep=0pt, minimum height=1.6cm, minimum width=2.8cm,  thick,scale=0.9},
 man1/.style={rectangle, rounded corners,draw=black!80,top color=white, bottom color=blue!50, align=center, node distance=5cm, inner sep=1pt, minimum height=1.6cm, minimum width=5.6cm, font=\small, thick, },]
\node[man] (A) {\textbf{ASY}\\ "Analyzing\\ subsystem"};
\node[man] (B) [below of=A] {\textbf{CSY}\\ "Countermeasure\\ subsystem"};
\node[man] (C) [below of=B] {\textbf{ESY}\\ "Evaluation\\ subsystem"};
\node[man1](D)[right of=A]{Display of contamination data.\\ Analysis and forecast of the \\ development of the contamination\\ based on data and \\ models' outputs};
\node[man1](E)[right of=B]{Simulation of the effects of\\ the available countermeasures,\\ judgment  of their attainability and \\ evaluation of the consequences \\ of each countermeasure.};
\node[man1](F)[right of=C]{Evaluation and rating of \\ the possible countermeasures by \\ considering their positive and  \\ negative sides.};
\node[single arrow, shape border rotate =270, draw=black!80,align=center, node distance=4cm,top color=white, bottom color=blue!50, thick] (G) at (10.5,-1.2) {\textbf{Emergency Actions:} \\ Evacuation;\\ Sheltering;\\ Protective measures;\\  \\ \textbf{Long term measures:}  \\ Resettlement; \\ Purification; \\ Agricultural measures; };
\draw [->,line width=0.5mm](A) -- (B);
\draw [->, line width=0.5mm](B) -- (C);
\draw[-, line width=0.5mm] (A)--(D);
\draw[-, line width=0.5mm] (B)--(E);
\draw[-, line width=0.5mm] (C)--(F);
\end{tikzpicture}
\caption{Conceptual structure of RODOS from \citet{Leonelli2013} and after \cite{raskob2009}.}
\label{fig:fromBri}
\end{center}
\end{figure*} 

As discussed, \gls{MCDA} techniques were included into both the \gls{CSY} and the \gls{ESY} components to evaluate and rank potential countermeasures. It is important to note here the relevance of the explanation module within the \gls{ESY}. Empirical research has shown that \glspl{DM} do not accept the suggestions of a system which does not provide a rationale for the outputs it produces \citep{Papamichail2013}, even if the system delivers accurate results. Furthermore, as extensively discussed in \citet{French2009}, the ultimate objective of a decision analysis is not in simply choosing a decision which is considered to be optimal according to certain criteria, but more importantly in developing a deeper understanding of the values and the uncertainties in the problem studied. These insights may then lead to an evolution of the \glspl{DM}' judgements and possibly to a revision of the whole model. This process is often called requisite modelling \citep{Phillips1984}. This idea was effectively included in the initial aims of both the development of RODOS and the International Chernobyl Project. Therefore \gls{RODOS} includes a variety of features to justify its outputs, as for example a natural language report generator to explain the ranking of the policies \citep{Papamichail2003}, sensitivity analysis graphs and their interpretations \citep{Papamichail2005}.

The \gls{ASY} subsystem is made of several different \textit{modules} (or component \glspl{DSS}), each providing estimates and forecasts for a different aspect of the emergency. Thus for example one of these modules concerns the workings of the source term which estimates the likelihood of a release of contamination from the plant. Another one includes atmospheric diffusion models describing the spread of the contamination. Additional modules model the effect of this spread might have because of the exposure of  humans, animals and plants. Although the \gls{ASY} modules are capable to work independently, in a comprehensive emergency management these are networked together in the sense that the outputs of some modules are used as inputs for others. Another important element to highlight from the above description is that the domains the \gls{ASY} modules aim at describing are particularly heterogeneous and therefore require knowledge on a variety of different disciplines. In Figure \ref{networkino}, from \citet{Leonelli2013}, is presented a plausible network of modules for use of a nuclear \gls{DSS}. Each vertex of the network corresponds to a module and two modules are connected by an arc if the outputs of the parent node are used are as inputs for the child node (see Appendix \ref{appendixB} for an introduction to graph theory). Furthermore the nodes are grouped in such a way that nodes with the same color represent modules concerning the same domain of expertise. Specifically, the grey vertices are concerned with engineering issues; the green ones with the environment; the blue ones by biological consequences; the brown, red and yellow ones by the political, medical and economical outcomes respectively.
\begin{figure*}
\begin{center}
\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=1.5cm,
                    semithick]
 \tikzstyle{every state}=[fill=white,draw,text=black, shape=rectangle, rounded corners,every text node part/.style={align=center}]
  \node[state]  (A)      [fill=black!20, draw=black!100, text=black]              {Power \\ plant};
  \node[state]         (B) [right = of A, draw=green!100, fill=green!20] {Water \\ dispersal};
   \node[state] (C) [draw=blue!100,  fill=blue!20,  right = of B]{Human \\ absorption};
\node[state] (D) [below of=A, fill=black!20, draw=black!100, text=black ]{Source \\  term};
\node[state](E)[below of=D, draw=green!100, fill=green!20]{Air \\ dispersal};
\node[state](F)[below of=B, draw=green!100, fill=green!20]{Deposition};
\node[state](H)[below of=F, draw=brown!100, fill=brown!20]{Political \\ effects};
\node[state] (L)[draw=blue!100,  fill=blue!20, text=black, below of =  C]{Animal \\ absorption};
\node[state](I)[below of=L, fill=yellow!20, draw=yellow!100]{Costs};
\node[state](G)[draw=red!100, fill=red!20, right=1cm of L]{Human \\  health};
\path (A) edge (D)
        (D) edge (B)
             edge (E)
         (B) edge (C)
              edge (L)
             edge (F)
          (E) edge (H)
               edge (F)
           (L) edge (C)
         (C) edge (G)
         (F) edge (L)
             edge (I)
          (L) edge (I)
         (G) edge (I)
          (I) edge (H);
\end{tikzpicture}
\end{center}
\caption{Plausible network for the modules of a nuclear decision support system. \label{networkino}}
\end{figure*} 

Each of the modules of the \gls{ASY} comprises of a set of methodologies, either deterministic or stochastic, to perform the task they were designed for. As an example, \citet{Turner1994} lists dozens of different atmospheric dispersion models that have been applied to different domains and systems. From the very early stages of the development of RODOS it was recognized \citep[after considerable debate, as noted in][]{Smith1997} that stochastic, and more specifically, Bayesian inferential methodologies should be used in such a nuclear \gls{DSS} to assimilate, combine and represent uncertainties. \citet{Smith1997} and our discussion in Section \ref{sec:early} extensively argued why it is reasonable to use this representation of uncertainty. Therefore different Bayesian models have been developed for the different modules, as for example a \gls{BN} for the workings of the source term \citep{Caminada2000}, a dynamic random forest for the atmospheric dispersion \citep{Smith1997} and a dynamic spatial model for the deposition module \citep{De2011}.  

It is also important to note here that in theory it could be possible for the \gls{ASY} to consist of a single big module which models the whole domain of nuclear emergency management. However, the provision of the system to be used across all the European countries required the software to support the integration of external programs developed by national research institutes of the many involved countries. Therefore, the \gls{ASY} had to be structured in this modular form, as a network of sub-models concerning the different elements of the emergency.

The description of the \gls{RODOS} system for nuclear emergency management has highlighted the complexity of the domains that current complex \glspl{DSS} aim at describing. The main points to inherit from this section are the following:
\begin{itemize}
\item inference and forecasting need to be distributed among the different modules within the \gls{DSS};
\item the judgements and beliefs of different individual with different expertise need to be included in the inferential process;
\item computations need to be fast to allow for real-time decision making in case of an emergency;
\item \gls{MCDA} techniques need to be included to reveal the true values of the \glspl{DM}.
\end{itemize}
In Section \ref{sec:current} we  comment on how the above points have been addressed in the literature of probabilistic \glspl{ES}.

Before proceeding with that discussion, it is important to underline the scientific relevance of a project like the development of \gls{RODOS}. Fortunately, the probability of occurrence of a nuclear accident is extremely low and a system like \gls{RODOS} is likely not to be used for real emergency management. At the same time, this implies that data and knowledge about this type of emergencies is scarce. Furthermore, the consequence of nuclear accident are and are perceived as severe and far-reaching \citep{Geldermann2009}. The system could be actually used for different types of nuclear threats, as for example dirty bombs, although this type of aid is not publicly stated in the mission of \gls{RODOS} \citep{Walle2008}. The process of the construction of \gls{RODOS} has actually deepened the understanding of both the values of potential \glspl{DM} and the possible evolutions of the emergency. As noted in \citet{Papamichail2013} nuclear emergency management has been at the forefront of stakeholder engagement and the use of decision conferencing, demonstrating the many benefits of these techniques. Nowadays \gls{RODOS} is not only used as an incommensurable educational tool for training personnel through exercises of scenario analysis, but also to highlight the areas in which current emergency management plans may not be adequate. \citet{Gering2013} reports a study where \gls{RODOS} was used to simulate emergencies with features similar to the recent outworkings of the Fukushima nuclear plant which showed that current methodologies have several major problems. 

It is therefore important to continue the development of methodologies to support \glspl{DM} in this sort of important policy choices. As we will point out in the following sections, the methods underpinning \gls{RODOS} have several flaws or at least aspects that can and need to be improved in order to provide a real comprehensive support to \glspl{DM}.

\section{Current Probabilistic Expert Systems}
\label{sec:current}
The complexity of the models that are currently build to tackle real applications, as the nuclear one, is increasing radically. The decomposition into local distributions that \glspl{BN} offer is not sufficient any more to both clearly depict the situation under study and allow for fast computations. Within the statistical graphical community, this was first recognized in \citet{Mahoney1996} for modelling military problems. The authors highlighted the need of an additional intermediate level of decomposition which breaks down the problem into a set of coupled components, both semantically and formally separable. Semantic separability implies that the component is meaningful to the user of the model, whilst formal separability means that the different components can be re-aggregated into a consistent probability model. This intermediate decomposition exactly corresponds to the division of the \gls{ASY} component into networked modules within the \gls{RODOS} system as in Figure \ref{networkino} and is indeed also called in \citet{Mahoney1996} \textit{modularization}.

\citet{Mahoney1996} refers to two attempts in the literature to create this intermediate level of modelling. The first one consists of the definition of similarity networks \citep{Heckerman1990}. These allowed the probability assessments of a complex diagnosis problem to be decomposed into the ones concerning subsets of related diseases. The overall probability specification could then be constructed by superimposition of the assessments over the subproblems. The second attempt is the definition of \glspl{MSBN} \citep{Xiang2002}. These can be thought of as a generalization of \glspl{BN} to the representation formalism of distributed multi-agent systems. In more details, a \glspl{MSBN} is a network including nodes representing agents which is sectioned into subnetworks, each including a particular agent. Recently these have been generalized to allow for dynamic recursions of probabilities  \citep{Xiang2011}. However, both these methodologies require a set of assumptions that in many applications can be fierce.  

Since these attempts do not allow for enough modelling flexibility, \citet{Mahoney1996} pointed towards the use of object oriented techniques in probabilistic modelling, similar to the ones used in programming languages. The authors noticed, as further stressed in \citet{Johnson2012}, that the object oriented paradigm provides features to simplify the modelling task in complex situations.  Specifically:
\begin{itemize}
\item \textbf{abstraction}/\textbf{encapsulation}: this means that some information is hidden to the user and its access is allowed only via a predefined interface. Modifications within these interfaces do not affect other parts of the system;
\item \textbf{modularization}/\textbf{reuse}: the system is composed of a set of loosely connected units, which, if the interfaces are held fixed, can be changed without having to rebuild the whole model.
\end{itemize} 
As we will see, these two main features will be included in our methodology and, by recalling the description of the nuclear \gls{DSS} \gls{RODOS}, are required if we are to develop support systems to be used in practice. \todo{Second forward reference.}

The object oriented route for probabilistic graphical models then started with the development of \glspl{OOBN} \citep{Koller97} and, concerning the modelling of complex situations, then continued in two main streams of research. The first one aimed at integrating first-order logic with Bayesian probability theory and culminated with the definition of \glspl{MEBN} \citep{Laskey2008, Laskey2009}. A \gls{MEBN} can be represented as a collection MFrags \citep{Laskey1997}, which can be thought of as \glspl{OOBN} with root nodes having known values. \citet{Laskey2008} proved that any sentence that can be expressed in first-order logic can be assigned a probability by \gls{MEBN} logic.

 The other strand of research discusses the use of \glspl{OOBN} as an integrating tool and introduced the concept of \glspl{IBN} \citep{Johnson2012a}. An \gls{IBN} can be thought of as a large \gls{OOBN} where different probabilities are elicited by different groups of experts. As we will see, these are a special case of the models we develop in this thesis, but still represent an important step forward to the representation and elicitation of complex probabilistic models.\todo{Third forward reference} \glspl{IBN} have been successfully applied to a variety of domains, for example to study the viability of cheetahs \citep{Johnson2013}, the blooming of Lyngbya (a particular seaweed) \citep{Johnson2014} and antitrust enforcement \citep{Mortera2013}. Although \glspl{IBN} can be seen as a special case of \glspl{IDSS}, we note that the focus in \citet{Johnson2012a} is mainly on the network engineering side of model development, rather than on the Bayesian conditions and assumption that allow for the integration of models which will be the focus of Chapter \ref{chapter3} of this thesis.  

A completely different route from the object oriented paradigm for expert systems has been proposed in \citet{Goldstein96}, which suggested the use of Bayes linear methodologies that do not require the specification of a full prior distribution \citep[see e.g.][]{Goldstein2007}. This approach simplifies both the computation and the elicitation burden, but does not provide in itself a viable alternative for the modelling of complex situations as the nuclear emergency management case described above.  We will see in Chapter \ref{chapter5} that Bayes linear methods can however be used within the framework of \glspl{IDSS} we develop in this thesis . Furthermore one of our results in Chapter \ref{chapter3} will generalize some of the theory of \citet{Goldstein96}. 

Although all the above models can be used to support management decision making as noted in \citet{Johnson2014}, these do not include any formal representation of both the available decision space and the preferences of the \gls{DM}, as required in the nuclear emergency management example. \glspl{ID} are a class of models that allow for a contemporaneous representation of random variables, utilities and decisions \citep{Bielza2011,Howard2005,Jensen2013}. There is now a vast literature on these models that we will briefly review in Section \ref{sec:id}. We importantly note that the literature about \glspl{ID} does not provide any insight on the use of these models for the representation and modelling of complex situations as the main focus of \gls{ID}'s research has been on the improvement of the speed computations, either exact or approximated. Thus, although \glspl{ID} include both decision and utilities, these models do not possess the expressive power of, for example, \glspl{IBN} for the representation of current applied problems.

Before concluding this section, we note that the description of the nuclear emergency management domain highlighted the geographic nature of many problems that \glspl{DM} have to deal with in practice. On one hand this simply means that the dimensionality of the overall problem grows since for example each variable of the large system might be recorded and observed at different locations in space. On the other it also raises issues specific of geographic modelling and concerning the use of geographic information systems in probabilistic modelling \citep{Stassopoulou1998}. Although we will not deal specifically with these sorts of issues, we recognize their importance in many applications and we note that there are now methods customized for the integration of geographic information systems with graphical models \citep{Laskey2010, Johnson2012}. However, in Section \ref{sec:exalgo} we will present two examples of how a geographic component can be included into an \gls{IDSS} in the simplest possible case.

\section{Decision Support Systems for the XXI Century}
\label{sec:decision}
Although the technology recently developed by the statistical community and reviewed in the previous section represents a big step forward in the modelling of complex issues, we note here that these methodologies still do not address many of the features of classes of problems as the nuclear emergency management of Section \ref{sec:nuclear}. 

First, because of the underlying \gls{OOBN} assumption, all the methods we introduced above assume that each sub-model is a graphical one. This is a restrictive assumption and, as we saw, many statistical models, not necessarily graphical, have been already developed for some of the \gls{ASY} components of \gls{RODOS}. Furthermore some of the modules in use are often not  probabilistic: this is the case for example of big simulators that model climate change. As we will see, the technology of \textit{emulators} \citep{Kennedy2001, OHagan2006} can then be used  to introduce a probabilistic distribution over the outputs of such simulators that can correspond to one element of an \gls{ASY} sequence. 

Second, \gls{RODOS} implemented \gls{MCDA} techniques to perform a formal decision analysis. Current statistical \glspl{ES} do not allow for such outputs and in general provide only probabilistic beliefs on a set of goal variables. Therefore, there is a need for new methods to be implemented in \glspl{DSS} that have the power of performing \glspl{MCDA}. In \gls{RODOS} this was based on value functions. We argue here though that for current \glspl{DSS} this is not sufficient and that \gls{MAUT}, which allows for a full uncertainty handling, needs to be used as a representation of \glspl{DM} preferences.      

Third, in such domains decision making is not usually the responsibility of a single individual but rather of groups. Decision centres will have the accountability and the responsibility of choosing a course of action and their judgements will be supported by best experts' knowledge. \glspl{DSS} need thus to provide both a theoretical framework allowing for such a collaborative purpose and the technology  to support prescriptive team decision making.   

Lastly, in order for this to be feasible in practice, both probabilistic inferences and preferential modelling need to be distributed, as in the \gls{ASY}, \gls{ESY}, \gls{CSY} structure of \gls{RODOS}. Therefore, the distributed nature of, for example, an \gls{IBN} needs to embellished with a formal preferential analysis, which entertains the same distributed nature, both formally and semantically. 

It is therefore fundamental to develop a framework with the above features in order to properly support \glspl{DM} in real current applications. As remarked by \citet{Mahoney1996}, the distributed nature of such a methodology is vital, since the following benefits would follow:
\begin{itemize}
\item computational tractability;
\item comprehensibility;
\item feasibility of testing.
\end{itemize}
Computational tractability derives from the local computation structure associated to distributed systems \citep[widely studied in machine learning, see e.g.][]{Peteiro2013,Rodriguez2011}. Distributed systems are more comprehensible since the overall outputs can be traced back to each subsytem's outputs, providing much clearer justifications to the delivered estimates. Finally feasibility of testing follows since each subsystem can be more straightforwardly tested and potentially upgraded than the whole system at once.  In the following we will highlight how the \gls{IDSS} methodology we introduce here entertains such features. \todo{reference forward!!!}

Similarly to the motivations that lead to the inception of graphical modelling techniques, we can notice that distributivity in complex systems aims at breaking down   a huge problem into ones of smaller dimension. In \citet{Spiegelhalter1993} such modelling approach was referred to as \textit{divide-and-conquer}. The methodology of \glspl{IDSS} uses the same idea to simplify decision analyses in highly multivariate and heterogeneous problems. We note here that such approach is commonly used in a variety of domains and subjects, as for example in composite likelihood methods \citep{Varin2011}, Markov chain Monte Carlo  schemes \citep{Lindsten2014} and parallel computing \citep{Chandy1998}.   

Although we used the nuclear emergency management scenario to motivate the need of the \gls{IDSS} methodology, it is important to note here that \glspl{IDSS} are relevant for most of current domain applications. \citet{Barons2014} discusses their use for food security, \citet{Smith2015} presents a simple example in forensics and we are currently starting to look at climate change applications. 

\section{Contributions of the Thesis}
\label{sec:contributions}
From a general viewpoint, the main contribution of the thesis is the definition of the \gls{IDSS} framework which allows for a formal distributed Bayesian decision analysis combining the beliefs of different of groups of experts to be performed. Throughout the thesis we will specify the conditions that allow for such definition in a variety of frameworks and discuss the advantages of this methodology. We will then develop a toolkit of methods for inference and decision making in \glspl{IDSS} as, for instance, propagation algorithms and symbolic inferential methods.

From a more specific/domain-based viewpoint, the results in this thesis extends current methods on a variety of aspects:
\begin{itemize}
\item statistical graphical modelling, although now well established and understood, is defined to work for single users. Here we extend the definition of several graphical models to work within a multi-expert domain in Section \ref{sec:idssex};
\item there are now several rules to combine expert judgement in the literature. Our work extends such rules for complex multivariate domains where the overall probability distribution can be described by means of a graphical model (see e.g. Propositions \ref{prop:combi} and \ref{prop:dyncombi});
\item a new concept of statistical causality tailored to the needs of \glspl{IDSS} is defined in Section \ref{sec:idsscaus}. We are able to show that Pearl's definition of causality \citep{Pearl2000} represents a special case of our definition;
\item we introduce a new class of utility factorizations in Section \ref{sec:comput} customized to the needs of \glspl{IDSS} which allow for a distributed computation of Bayesian expected utilities in the multi-expert domains we address;
\item we  introduce in Section \ref{sec:algorithms} new utility-based propagation algorithms for the distributed computation of expected utility scores in \glspl{IDSS}. Some of the current evaluation algorithms of decisional structures can be seen as special cases of the ones we define here;
\item by studying decision making in \glspl{IDSS} from an algebraic perspective, we identify minimal sets of independence statements assuring the system provides rational decision support. This recognition leads us to define in Section \ref{sec:momind} new types of independence tailored to the needs of \glspl{IDSS}; 
\item we develop in Section \ref{sec:short} new symbolic approaches to decision making in different frameworks, which extends current symbolic methods for probabilistic reasoning in graphical models.
\end{itemize}

\section{Structure of the Thesis}
\label{sec:structure}
Having extensively discussed the need for the definition of \glspl{IDSS} and reviewed other statistical approaches to model complex domains in this first chapter, we proceed in Chapter \ref{chapter2} with a review of classic Bayesian decision analysis methods for single \glspl{DM}. In this chapter we discuss  standard Bayesian reasoning and the \gls{SEU} model for decision making. We then introduce a variety of probabilistic, utility and decision models that can be used within the \gls{SEU} models. We further survey issues associated to group decision making and the use of expert judgement. 

In Chapter \ref{chapter3} we introduce \glspl{IDSS} and a set of axioms that can guarantee their existence. We then discuss what makes a good \gls{IDSS}, in a nutshell a distributed and formally separable one, and generic conditions that can ensure a good \gls{IDSS} both a priori and after the introduction of both observational and experimental data.  We then show that many of the statistical models discussed in Chapter \ref{chapter2} can be used as an underlying probabilistic framework for \gls{IDSS} and the conditions that these need to entertain. 

We then consider in Chapter \ref{chapter4} a large class of \glspl{IDSS} based on flexible probability and utility models. For this class we develop distributed utility-based message passing algorithms that allow for the exact computation of expected utility scores from the outputs of the individual modules of the \gls{IDSS}. We then exemplify the methodology at the end of the chapter in a large variety of domains. 

The examples of Chapter \ref{chapter4} show that the expressions used by the \gls{IDSS} to rank the available policies are polynomial functions of the outputs of the component \glspl{DSS}. This recognition lead us to analyse \glspl{IDSS} in Chapter \ref{chapter5} from an algebraic viewpoint and to define independence concepts following from the polynomial relationships existing from these outputs. This chapter will also introduce symbolic techniques for particular statistical models in \glspl{IDSS}, which, as we will argue extensively, are intimately linked with algebraic analyses of statistical models. 

We conclude the thesis in Chapter \ref{chapter6}, where we summarize the main results of the thesis and discuss possible extensions of the methods developed in the thesis. 

For convenience of the reader, the thesis also include 5 appendices. In Appendix \ref{appendixA} we collect the proofs of the results presented in the main body of the thesis. Appendix \ref{appendixB} introduces the required terminology of graph theory, whilst Appendix \ref{appendixC} consists of basic definitions of polynomial algebra. In Appendix \ref{appendixD} we report our computer algebra code to implement the methods we introduce in Section \ref{sec:symbolic}. Appendix \ref{appendixE} reviews basic statistical distributional theory and the Bayesian models that are used throughout the thesis.  